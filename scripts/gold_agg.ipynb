{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db2d01cb-6f6e-40ff-9a29-f2e485ccb10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, explode, from_json, col, current_date,current_timestamp, lit, to_date, month\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StringType, StructType, StructField, ArrayType\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a99c0881-c071-4e80-9b0c-96b2c44d52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG_URI = \"http://nessie:19120/api/v1\"\n",
    "WAREHOUSE = \"s3a://gold/\"              \n",
    "STORAGE_URI = \"http://minio:9000\"\n",
    "AWS_ACCESS_KEY = \"admin\"\n",
    "AWS_SECRET_KEY = \"password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ed0dd85-ce6d-4d5e-895e-e1a01ea68874",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setAppName('silver_transform')\n",
    "\n",
    "        # 📦 Dependencias necesarias\n",
    "        .set(\"spark.jars.packages\", \",\".join([\n",
    "            \"org.postgresql:postgresql:42.7.3\",\n",
    "            \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0\",\n",
    "            \"org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1\",\n",
    "            \"software.amazon.awssdk:bundle:2.24.8\",\n",
    "            \"software.amazon.awssdk:url-connection-client:2.24.8\",\n",
    "            \"org.apache.hadoop:hadoop-aws:3.3.4\"\n",
    "        ]))\n",
    "\n",
    "        # 🧩 Extensiones Iceberg + Nessie\n",
    "        .set(\"spark.sql.extensions\", \",\".join([\n",
    "            \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "            \"org.projectnessie.spark.extensions.NessieSparkSessionExtensions\"\n",
    "        ]))\n",
    "\n",
    "        # 🗂️ Catálogo Nessie\n",
    "        .set(\"spark.sql.catalog.nessie\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "        .set(\"spark.sql.catalog.nessie.catalog-impl\", \"org.apache.iceberg.nessie.NessieCatalog\")\n",
    "        .set(\"spark.sql.catalog.nessie.uri\", CATALOG_URI)\n",
    "        .set(\"spark.sql.catalog.nessie.ref\", \"main\")\n",
    "        .set(\"spark.sql.catalog.nessie.authentication.type\", \"NONE\")\n",
    "        .set(\"spark.sql.catalog.nessie.io-impl\", \"org.apache.iceberg.hadoop.HadoopFileIO\")\n",
    "        .set(\"spark.sql.catalog.nessie.warehouse\", WAREHOUSE)\n",
    "\n",
    "        # ☁️ Configuración S3A para MinIO\n",
    "        .set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "        .set(\"spark.hadoop.fs.s3a.endpoint\", STORAGE_URI)\n",
    "        .set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "        .set(\"spark.hadoop.fs.s3a.access.key\", AWS_ACCESS_KEY)\n",
    "        .set(\"spark.hadoop.fs.s3a.secret.key\", AWS_SECRET_KEY)\n",
    "        .set(\"spark.hadoop.fs.s3a.aws.credentials.provider\",\n",
    "             \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "        .set(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "\n",
    "        # ⚡ Optimizaciones de ejecución\n",
    "        .set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "        .set(\"spark.sql.parquet.filterPushdown\", \"true\")\n",
    "        .set(\"spark.sql.parquet.mergeSchema\", \"false\")\n",
    "        .set(\"spark.sql.shuffle.partitions\", \"64\")  # 🔧 más particiones para distribuir carga\n",
    "        .set(\"spark.sql.files.maxPartitionBytes\", \"64MB\")  # ⚖️ reduce tamaño de tarea para evitar saturación\n",
    "\n",
    "        .set(\"spark.driver.memory\", \"5g\")                     # Driver usa hasta 5 GB (de los 6g disponibles)\n",
    "        .set(\"spark.executor.memory\", \"6g\")                   # Cada executor usa hasta 6 GB (de los 8g disponibles)\n",
    "        .set(\"spark.executor.cores\", \"4\")                     # Más núcleos por executor para paralelismo\n",
    "        .set(\"spark.driver.maxResultSize\", \"2g\")              # Aumenta el límite de resultados del driver\n",
    "        .set(\"spark.network.timeout\", \"600s\")                 # Timeout más generoso para cargas grandes\n",
    "        .set(\"spark.executor.heartbeatInterval\", \"60s\")       # Latido coherente con el timeout\n",
    "        \n",
    "        # ⚙️ Escritura\n",
    "        .set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "235a290e-595d-4f91-b69d-75675d4e38e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Started\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n",
    "print(\"Spark Session Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e7f4cb9-922a-4175-8623-fafb4a441fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = spark.read.table(\"nessie.silver.posts\")\n",
    "votes_df = spark.read.table(\"nessie.silver.votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a6c97af-4cd1-413a-9715-0984bd5ccadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df.createOrReplaceTempView(\"posts_view\")\n",
    "votes_df.createOrReplaceTempView(\"votes_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f7cf4ee-7e83-445b-b370-2fd4d98e5f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_stats_per_post = spark.sql(\"\"\"\n",
    "    WITH valid_votes AS (\n",
    "        SELECT\n",
    "            v.post_id_clean AS post_id,\n",
    "            v.vote_type_id_clean,\n",
    "            v.creation_ts,\n",
    "            v.creation_year,\n",
    "            DATE_FORMAT(v.creation_ts, 'yyyy-MM') AS year_month\n",
    "        FROM votes_view v\n",
    "        WHERE v.post_id_clean IS NOT NULL AND v.post_id_clean != -1\n",
    "              AND v.vote_type_id_clean != -1\n",
    "    ),\n",
    "    vote_summary AS (\n",
    "        SELECT\n",
    "            post_id,\n",
    "            YEAR(creation_ts) AS year,\n",
    "            MONTH(creation_ts) AS month,\n",
    "            SUM(CASE WHEN vote_type_id_clean IN (2, 18, 20, 21, 32) THEN 1 ELSE 0 END) AS upvotes,\n",
    "            SUM(CASE WHEN vote_type_id_clean IN (3, 33) THEN 1 ELSE 0 END) AS downvotes,\n",
    "            COUNT(*) AS total_votes\n",
    "        FROM valid_votes\n",
    "        GROUP BY post_id, YEAR(creation_ts), MONTH(creation_ts)\n",
    "    ),\n",
    "    posts_enriched AS (\n",
    "        SELECT\n",
    "            p.Id AS post_id,\n",
    "            p.Score AS base_score,\n",
    "            p.ViewCount,\n",
    "            p.AnswerCount,\n",
    "            p.CommentCount,\n",
    "            p.FavoriteCount,\n",
    "            p.PostTypeId,\n",
    "            p.CreationDate,\n",
    "            p.LastActivityDate,\n",
    "            CASE p.PostTypeId\n",
    "                WHEN 1 THEN 'Question'\n",
    "                WHEN 2 THEN 'Answer'\n",
    "                WHEN 3 THEN 'Orphaned Tag Wiki'\n",
    "                WHEN 4 THEN 'Tag Wiki Excerpt'\n",
    "                WHEN 5 THEN 'Tag Wiki'\n",
    "                WHEN 6 THEN 'Moderator Nomination'\n",
    "                WHEN 7 THEN 'Wiki Placeholder'\n",
    "                WHEN 8 THEN 'Privilege Wiki'\n",
    "                WHEN 9 THEN 'Article'\n",
    "                WHEN 10 THEN 'Help Article'\n",
    "                WHEN 12 THEN 'Collection'\n",
    "                WHEN 13 THEN 'Moderator Questionnaire Response'\n",
    "                WHEN 14 THEN 'Announcement'\n",
    "                WHEN 15 THEN 'Collective Discussion'\n",
    "                WHEN 17 THEN 'Collective Collection'\n",
    "                ELSE 'Other'\n",
    "            END AS post_type\n",
    "        FROM posts_view p\n",
    "    )\n",
    "    SELECT\n",
    "        ps.post_id,\n",
    "        ps.post_type,\n",
    "        vs.year,\n",
    "        vs.month,\n",
    "        ps.ViewCount,\n",
    "        ps.AnswerCount,\n",
    "        ps.CommentCount,\n",
    "        ps.FavoriteCount,\n",
    "        COALESCE(vs.upvotes, 0) AS upvotes,\n",
    "        COALESCE(vs.downvotes, 0) AS downvotes,\n",
    "        COALESCE(vs.total_votes, 0) AS total_votes,\n",
    "        (ps.base_score + COALESCE(vs.upvotes, 0) - COALESCE(vs.downvotes, 0)) AS score,\n",
    "        ROUND(\n",
    "            CASE WHEN vs.total_votes > 0 THEN vs.upvotes / vs.total_votes ELSE 0 END, 3\n",
    "        ) AS upvote_pct,\n",
    "        ROUND(\n",
    "            CASE WHEN vs.total_votes > 0 THEN vs.downvotes / vs.total_votes ELSE 0 END, 3\n",
    "        ) AS downvote_pct,\n",
    "        CURRENT_TIMESTAMP() AS load_date\n",
    "    FROM posts_enriched ps\n",
    "    LEFT JOIN vote_summary vs\n",
    "        ON ps.post_id = vs.post_id\n",
    "    WHERE vs.year = 2023 AND vs.month IS NOT NULL\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de2bcd81-34ef-4fca-abdb-9ab12cbba111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Namespace nessie.gold creado si no existía.\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS nessie.gold\")\n",
    "print(\"✅ Namespace nessie.gold creado si no existía.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30419acc-c1f4-4a2e-984e-20b36bd6bde6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Registrar como vista temporal para el MERGE\n",
    "vote_stats_per_post.createOrReplaceTempView(\"vote_stats_updates\")\n",
    "table_exists = spark.catalog.tableExists(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebdb9b81-151c-4035-ab14-30300273b076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusionando datos en la tabla existente nessie.gold.vote_stats_per_post...\n",
      "✅ Datos fusionados exitosamente en nessie.gold.vote_stats_per_post usando MERGE de Iceberg con granularidad por fecha.\n"
     ]
    }
   ],
   "source": [
    "if not table_exists:\n",
    "    print(f\"⚙️ La tabla {table_path} no existe. Creándola...\")\n",
    "    vote_stats_per_post.writeTo(table_path).create()\n",
    "    print(f\"✅ Tabla {table_path} creada exitosamente.\")\n",
    "else:\n",
    "    print(f\"Fusionando datos en la tabla existente {table_path}...\")\n",
    "    spark.sql(f\"\"\"\n",
    "        MERGE INTO {table_path} AS target\n",
    "        USING vote_stats_updates AS source\n",
    "        ON target.post_id = source.post_id \n",
    "           AND target.year = source.year \n",
    "           AND target.month = source.month\n",
    "        WHEN MATCHED THEN UPDATE SET *\n",
    "        WHEN NOT MATCHED THEN INSERT *\n",
    "    \"\"\")\n",
    "    print(f\"✅ Datos fusionados exitosamente en {table_path} usando MERGE de Iceberg con granularidad por fecha.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f1f5dbc-09cd-4524-8585-0400e666d9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- post_id: long (nullable = true)\n",
      " |-- post_type: string (nullable = false)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- ViewCount: long (nullable = true)\n",
      " |-- AnswerCount: long (nullable = true)\n",
      " |-- CommentCount: long (nullable = true)\n",
      " |-- FavoriteCount: long (nullable = true)\n",
      " |-- upvotes: long (nullable = false)\n",
      " |-- downvotes: long (nullable = false)\n",
      " |-- total_votes: long (nullable = false)\n",
      " |-- score: long (nullable = true)\n",
      " |-- upvote_pct: double (nullable = true)\n",
      " |-- downvote_pct: double (nullable = true)\n",
      " |-- load_date: timestamp (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "493812"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opcional: Verificar el esquema o conteo\n",
    "vote_stats_per_post.printSchema()\n",
    "vote_stats_per_post.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca8f9596-c54b-4a64-bde6-6372d21188ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----+-----+---------+-----------+------------+-------------+-------+---------+-----------+-----+----------+------------+--------------------+\n",
      "| post_id|post_type|year|month|ViewCount|AnswerCount|CommentCount|FavoriteCount|upvotes|downvotes|total_votes|score|upvote_pct|downvote_pct|           load_date|\n",
      "+--------+---------+----+-----+---------+-----------+------------+-------------+-------+---------+-----------+-----+----------+------------+--------------------+\n",
      "|70547323| Question|2023|    3|      399|          0|           1|            0|      2|        0|          2|    5|       1.0|         0.0|2025-10-15 04:29:...|\n",
      "|70547323| Question|2023|    1|      399|          0|           1|            0|      1|        0|          1|    4|       1.0|         0.0|2025-10-15 04:29:...|\n",
      "|70547373| Question|2023|    3|     4694|          2|           0|            0|      1|        0|          1|    3|       1.0|         0.0|2025-10-15 04:29:...|\n",
      "|70547437|   Answer|2023|    4|        0|          0|           0|            0|      1|        0|          1|    7|       1.0|         0.0|2025-10-15 04:29:...|\n",
      "|70547466| Question|2023|    2|     1243|          1|           0|            0|      1|        0|          1|    3|       1.0|         0.0|2025-10-15 04:29:...|\n",
      "+--------+---------+----+-----+---------+-----------+------------+-------------+-------+---------+-----------+-----+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vote_stats_per_post.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "372eaf54-c289-48ec-af30-ae23b43afd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac55af4-a983-4660-8f88-308d67e9fdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
