{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac42257-f1db-4bf6-8634-8543fe85be09",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from json import dumps\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, explode, from_json, col, current_date,current_timestamp, lit, row_number, when, decode, regexp_replace, trim\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import StringType, StructType, StructField, ArrayType, DecimalType\n",
    "import datetime \n",
    "import requests\n",
    "import urllib3\n",
    "from datetime import datetime,date\n",
    "import pytz\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import boto3\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef02f49-0602-447f-8f26-58b08c6f73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID=\"admin\"\n",
    "AWS_SECRET_ACCESS_KEY=\"password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e633b952-a3c4-4025-884b-4e847de58bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '186D866FE7999190',\n",
       "  'HostId': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-length': '540',\n",
       "   'content-type': 'application/xml',\n",
       "   'server': 'MinIO',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'Origin, Accept-Encoding',\n",
       "   'x-amz-bucket-region': 'us-east-1',\n",
       "   'x-amz-id-2': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "   'x-amz-request-id': '186D866FE7999190',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'x-ratelimit-limit': '1998',\n",
       "   'x-ratelimit-remaining': '1998',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Sat, 11 Oct 2025 19:27:24 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'bronze',\n",
       "   'CreationDate': datetime.datetime(2025, 10, 11, 18, 50, 3, 77000, tzinfo=tzlocal())},\n",
       "  {'Name': 'gold',\n",
       "   'CreationDate': datetime.datetime(2025, 10, 11, 19, 8, 23, 613000, tzinfo=tzlocal())},\n",
       "  {'Name': 'silver',\n",
       "   'CreationDate': datetime.datetime(2025, 10, 11, 19, 8, 16, 296000, tzinfo=tzlocal())}],\n",
       " 'Owner': {'DisplayName': 'minio',\n",
       "  'ID': '02d6176db174dc93cb1b899f7c6078f08654445fe8cf1b6ce98d8855f66bdbf4'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3', endpoint_url='http://minio:9000',\n",
    "                  aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "                  aws_secret_access_key=AWS_SECRET_ACCESS_KEY)\n",
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8259119-e489-4b29-8777-0cf74cd46291",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG_URI = \"http://nessie:19120/api/v1\" \n",
    "WAREHOUSE = \"s3://silver/\"               \n",
    "STORAGE_URI = \"http://minio:9000\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35f79650-a6a3-4ab4-a69b-55aae9ce03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "    .setAppName('silver_layer_transformation')\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # DEPENDENCIAS ICEBERG, NESSIE Y AWS\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    .set('spark.jars.packages', \n",
    "         'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,'\n",
    "         'org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1,'\n",
    "         'software.amazon.awssdk:bundle:2.24.8,'\n",
    "         'software.amazon.awssdk:url-connection-client:2.24.8,'\n",
    "         'org.apache.hadoop:hadoop-aws:3.2.0,'\n",
    "         'com.amazonaws:aws-java-sdk-bundle:1.11.534')\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # CATÃLOGO ICEBERG CON NESSIE\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    .set('spark.sql.extensions', \n",
    "         'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,'\n",
    "         'org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "    .set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "    .set('spark.sql.catalog.nessie.uri', CATALOG_URI)\n",
    "    .set('spark.sql.catalog.nessie.ref', 'main')\n",
    "    .set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    "    .set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "    .set('spark.sql.catalog.nessie.warehouse', WAREHOUSE)\n",
    "    .set('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    "    .set('spark.sql.catalog.nessie.s3.endpoint', STORAGE_URI)\n",
    "    .set('spark.sql.catalog.nessie.s3.path-style-access', 'true')\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # CONFIGURACIÃ“N S3/MINIO (para lectura/escritura directa)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    .set('spark.hadoop.fs.s3a.endpoint', STORAGE_URI)\n",
    "    .set('spark.hadoop.fs.s3a.access.key', AWS_ACCESS_KEY_ID)\n",
    "    .set('spark.hadoop.fs.s3a.secret.key', AWS_SECRET_ACCESS_KEY)\n",
    "    .set('spark.hadoop.fs.s3a.path.style.access', 'true')\n",
    "    .set('spark.hadoop.fs.s3a.connection.ssl.enabled', 'false')\n",
    "    .set('spark.hadoop.fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')\n",
    "    .set('spark.hadoop.fs.s3a.aws.credentials.provider',\n",
    "                'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider')\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # MEMORIA Y RENDIMIENTO\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "      .set('spark.driver.memory', '3g')      # Antes: 5g\n",
    "    .set('spark.executor.memory', '4g')    # Antes: 8g\n",
    "    .set('spark.sql.adaptive.enabled', 'true')  # OptimizaciÃ³n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136f2455-a632-4372-9348-0ce4ffb56ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Started\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n",
    "print(\"Spark Session Started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3f93237-7607-4b9d-890b-10a4135dbbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_2022 = spark.read.parquet(\"s3a://bronze/votes/2022/votes_2022.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0023be3-6042-45d4-b1ff-3802bd3198f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_2022 = votes_2022.withColumn(\"load_date\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "771d0af1-871e-4fdb-88c6-c5815bd56b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_2023 = spark.read.parquet(\"s3a://bronze/votes/2023/votes_2023.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a3afef4-55f0-46be-a8f0-8e693b5a8e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_2023 = votes_2023.withColumn(\"load_date\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "488b5d1e-a612-4033-bafc-1223818f0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_2022 = spark.read.parquet(\"s3a://bronze/comments/_2022/1760209491.8317685.cc1709bc87.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5d613c9-5678-4995-884a-25c52529a668",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_2022 = comments_2022.withColumn(\"load_date\", current_timestamp())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6e91400-b2c2-4dd2-85c9-4398ab685f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_2023 = spark.read.parquet(\"s3a://bronze/comments/2023/comments_2023.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82793a98-bccd-4ebb-a096-37a384a2bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_2023 = comments_2023.withColumn(\"load_date\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49f5b32c-a523-48a2-b292-753b013e8770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS nessie.silver\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63be5ea0-ac55-484e-a011-70fe3aedd93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: long (nullable = true)\n",
      " |-- PostId: long (nullable = true)\n",
      " |-- VoteTypeId: long (nullable = true)\n",
      " |-- CreationDate: timestamp (nullable = true)\n",
      " |-- UserId: long (nullable = true)\n",
      " |-- BountyAmount: decimal(20,0) (nullable = true)\n",
      " |-- load_date: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "votes_2022.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb3d8c96-5093-4761-888d-24d895b4309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- post_id: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- text: binary (nullable = true)\n",
      " |-- creation_date: timestamp (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- user_display_name: binary (nullable = true)\n",
      " |-- load_date: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comments_2022.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_snake_case(df):\n",
    "    \"\"\"\n",
    "    Convierte nombres de columna PascalCase a snake_case\n",
    "    y elimina columnas tÃ©cnicas que empiezan con '_dlt_'\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def pascal_to_snake(name):\n",
    "        \"\"\"Convierte PascalCase a snake_case\"\"\"\n",
    "        # Insertar _ antes de mayÃºsculas (excepto la primera)\n",
    "        s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "        # Insertar _ antes de mayÃºsculas seguidas de minÃºsculas\n",
    "        return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\n",
    "    \n",
    "    # Convertir columnas a snake_case\n",
    "    renamed_count = 0\n",
    "    for col_name in df.columns:\n",
    "        # Saltar columnas tÃ©cnicas\n",
    "        if col_name.startswith('_dlt_'):\n",
    "            continue\n",
    "        \n",
    "        # Si ya estÃ¡ en snake_case, saltar\n",
    "        if col_name.islower() or '_' in col_name:\n",
    "            continue\n",
    "        \n",
    "        # Convertir PascalCase a snake_case\n",
    "        snake_case = pascal_to_snake(col_name)\n",
    "        \n",
    "        if snake_case != col_name:\n",
    "            df = df.withColumnRenamed(col_name, snake_case)\n",
    "            renamed_count += 1\n",
    "    \n",
    "    # Eliminar columnas tÃ©cnicas\n",
    "    dlt_columns = [c for c in df.columns if c.startswith('_dlt_')]\n",
    "    if dlt_columns:\n",
    "        df = df.drop(*dlt_columns)\n",
    "        print(f\"Removed technical columns: {', '.join(dlt_columns)}\")\n",
    "    \n",
    "    if renamed_count > 0:\n",
    "        print(f\"Renamed {renamed_count} columns to snake_case\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe48b2-8cb1-4419-bbe8-13e709c8bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_votes_dataframe(df, year):\n",
    "    print(f\"ðŸ§¹ Limpiando Votes {year}...\")\n",
    "\n",
    "    # ðŸ”¸ Convertir tipo de dato\n",
    "    df_clean = df.withColumn(\"BountyAmount\", col(\"BountyAmount\").cast(DecimalType(10, 2)))\n",
    "\n",
    "    # ðŸ”¸ Definir ventana para deduplicar (con base en las columnas relevantes)\n",
    "    window = (\n",
    "        Window\n",
    "        .partitionBy(\"PostId\", \"VoteTypeId\", \"UserId\", \"CreationDate\")\n",
    "        .orderBy(\"Id\")\n",
    "    )\n",
    "\n",
    "    # ðŸ”¸ Identificar y eliminar duplicados\n",
    "    df_dedup = (\n",
    "        df_clean\n",
    "        .withColumn(\"row_num\", row_number().over(window))\n",
    "        .filter(col(\"row_num\") == 1)  # conserva solo el primero\n",
    "        .drop(\"row_num\")\n",
    "    )\n",
    "\n",
    "    # ðŸ”¸ Calcular estadÃ­sticas de limpieza\n",
    "    original_count = df.count()\n",
    "    dedup_count = df_dedup.count()\n",
    "    duplicates_removed = original_count - dedup_count\n",
    "\n",
    "    print(f\"  âœ“ Eliminados {duplicates_removed:,} votos duplicados de {original_count:,}\")\n",
    "    print(f\"âœ… Limpieza completa para Votes {year}\")\n",
    "\n",
    "    df = normalize_to_snake_case(df_dedup)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3559390-e397-4307-87fc-57953748c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments_dataframe(df, year):\n",
    "\n",
    "    print(f\"Limpiando comments {year}...\")\n",
    "\n",
    "    df = normalize_to_snake_case(df)\n",
    "\n",
    "    df_clean = (\n",
    "        df\n",
    "        .withColumn(\"text\", decode(col(\"text\"), \"UTF-8\"))\n",
    "        .withColumn(\"user_display_name\", decode(col(\"user_display_name\"), \"UTF-8\"))\n",
    "    )\n",
    "    \n",
    "    df_clean = (\n",
    "        df_clean\n",
    "        .withColumn(\"user_display_name\", \n",
    "                    when(col(\"user_display_name\").isNotNull(),\n",
    "                         regexp_replace(trim(col(\"user_display_name\")), r'\\s+', ' '))\n",
    "                    .otherwise(None))\n",
    "    \n",
    "        .withColumn(\"text\",\n",
    "                    when(col(\"text\").isNotNull(),\n",
    "                         regexp_replace(col(\"text\"), r'[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F]', ''))\n",
    "                    .otherwise(None))\n",
    "    )\n",
    "    \n",
    "    print(f\"Limpieza para comments {year}\")\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d490465-cd15-4968-ba48-5788bc69bc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS nessie.silver.votes (\n",
    "        Id BIGINT,\n",
    "        PostId BIGINT,\n",
    "        VoteTypeId BIGINT,\n",
    "        CreationDate TIMESTAMP,\n",
    "        UserId BIGINT,\n",
    "        BountyAmount DECIMAL(10,2),\n",
    "        load_date TIMESTAMP NOT NULL\n",
    "    )\n",
    "    USING iceberg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c1a60",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS nessie.silver.comments (\n",
    "    id BIGINT,\n",
    "    post_id BIGINT,\n",
    "    score BIGINT,\n",
    "    text STRING,\n",
    "    creation_date TIMESTAMP,\n",
    "    user_id BIGINT,\n",
    "    user_display_name STRING,\n",
    "    load_date TIMESTAMP NOT NULL\n",
    ")\n",
    "USING iceberg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a330d8c3-e808-4014-a930-1645848e1522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark reiniciado\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "print(\"âœ… Spark reiniciado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18a4d78f-98ab-4a74-8ec4-164294aa50e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Limpiando Votes 2022...\n",
      "  âœ“ Eliminados 1,447,233 votos duplicados de 15,851,534\n",
      "âœ… Limpieza completa para Votes 2022\n"
     ]
    }
   ],
   "source": [
    "votes2022_clean=clean_votes_dataframe(votes_2022,2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddf8d41a-9d68-49a9-a7b8-9b6c5fb0584d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Limpiando Votes 2023...\n",
      "  âœ“ Eliminados 926,899 votos duplicados de 11,209,693\n",
      "âœ… Limpieza completa para Votes 2023\n"
     ]
    }
   ],
   "source": [
    "votes2023_clean=clean_votes_dataframe(votes_2023,2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "028e1cd3-6ea7-4b7b-8f33-3369f714e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpiando comments 2022...\n",
      "Limpieza para comments 2022\n"
     ]
    }
   ],
   "source": [
    "comments2022_clean=clean_comments_dataframe(comments_2022,2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bce486da-a2e1-4e44-a515-453f97c5435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpiando comments 2023...\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `user_display_name` cannot be resolved. Did you mean one of the following? [`UserDisplayName`, `UserId`, `load_date`, `CreationDate`, `Id`].;\n'Project [Id#169L, PostId#170L, Score#171L, text#357, CreationDate#173, UserId#174L, UserDisplayName#175, load_date#183, decode('user_display_name, UTF-8) AS user_display_name#366]\n+- Project [Id#169L, PostId#170L, Score#171L, decode(text#172, UTF-8) AS text#357, CreationDate#173, UserId#174L, UserDisplayName#175, load_date#183]\n   +- Project [Id#169L, PostId#170L, Score#171L, Text#172, CreationDate#173, UserId#174L, UserDisplayName#175, current_timestamp() AS load_date#183]\n      +- Relation [Id#169L,PostId#170L,Score#171L,Text#172,CreationDate#173,UserId#174L,UserDisplayName#175] parquet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m comments2023_clean\u001b[38;5;241m=\u001b[39m\u001b[43mclean_comments_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomments_2023\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2023\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 8\u001b[0m, in \u001b[0;36mclean_comments_dataframe\u001b[0;34m(df, year)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_comments_dataframe\u001b[39m(df, year):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLimpiando comments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     df_clean \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      6\u001b[0m         \u001b[43mdf\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUTF-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m----> 8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_display_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_display_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUTF-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     df_clean \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     12\u001b[0m         df_clean\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_display_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[38;5;241m.\u001b[39motherwise(\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLimpieza para comments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyspark/sql/dataframe.py:5176\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5173\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5174\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   5175\u001b[0m     )\n\u001b[0;32m-> 5176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `user_display_name` cannot be resolved. Did you mean one of the following? [`UserDisplayName`, `UserId`, `load_date`, `CreationDate`, `Id`].;\n'Project [Id#169L, PostId#170L, Score#171L, text#357, CreationDate#173, UserId#174L, UserDisplayName#175, load_date#183, decode('user_display_name, UTF-8) AS user_display_name#366]\n+- Project [Id#169L, PostId#170L, Score#171L, decode(text#172, UTF-8) AS text#357, CreationDate#173, UserId#174L, UserDisplayName#175, load_date#183]\n   +- Project [Id#169L, PostId#170L, Score#171L, Text#172, CreationDate#173, UserId#174L, UserDisplayName#175, current_timestamp() AS load_date#183]\n      +- Relation [Id#169L,PostId#170L,Score#171L,Text#172,CreationDate#173,UserId#174L,UserDisplayName#175] parquet\n"
     ]
    }
   ],
   "source": [
    "comments2023_clean=clean_comments_dataframe(comments_2023,2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_consolidate_votes(df_2022, df_2023):\n",
    "    \"\"\"Merge y consolidaciÃ³n de datos de Votes\"\"\"\n",
    "    print(\"ðŸ”„ Realizando merge de Votes 2022 y 2023...\")\n",
    "\n",
    "    \n",
    "    # Combinar DataFrames\n",
    "    votes_combined = df_2022.unionByName(df_2023)\n",
    "    \n",
    "    # EstadÃ­sticas\n",
    "    count_2022 = df_2022.count()\n",
    "    count_2023 = df_2023.count()\n",
    "    total_count = votes_combined.count()\n",
    "    \n",
    "    print(f\"  ðŸ“Š EstadÃ­sticas Votes:\")\n",
    "    print(f\"    â€¢ 2022: {count_2022:,} registros\")\n",
    "    print(f\"    â€¢ 2023: {count_2023:,} registros\")\n",
    "    print(f\"    â€¢ Total: {total_count:,} registros\")\n",
    "    \n",
    "    # Escribir en Iceberg\n",
    "    votes_combined.writeTo(\"nessie.silver.votes\").append()\n",
    "    print(\"âœ… Merge completado para Votes\")\n",
    "    \n",
    "    return votes_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd162d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def merge_and_consolidate_comments(df_2022, df_2023):\n",
    "    \"\"\"Merge y consolidaciÃ³n de datos de Comments\"\"\"\n",
    "    print(\"ðŸ”„ Realizando merge de Comments 2022 y 2023...\")\n",
    "    \n",
    "    # Agregar timestamp de carga si no existe\n",
    "    if \"load_date\" not in df_2022.columns:\n",
    "        df_2022 = df_2022.withColumn(\"load_date\", current_timestamp())\n",
    "    if \"load_date\" not in df_2023.columns:\n",
    "        df_2023 = df_2023.withColumn(\"load_date\", current_timestamp())\n",
    "    \n",
    "    # Combinar DataFrames\n",
    "    comments_combined = df_2022.unionByName(df_2023)\n",
    "    \n",
    "    # EstadÃ­sticas\n",
    "    count_2022 = df_2022.count()\n",
    "    count_2023 = df_2023.count()\n",
    "    total_count = comments_combined.count()\n",
    "    \n",
    "    print(f\"  ðŸ“Š EstadÃ­sticas Comments:\")\n",
    "    print(f\"    â€¢ 2022: {count_2022:,} registros\")\n",
    "    print(f\"    â€¢ 2023: {count_2023:,} registros\")\n",
    "    print(f\"    â€¢ Total: {total_count:,} registros\")\n",
    "    \n",
    "    # Escribir en Iceberg\n",
    "    comments_combined.writeTo(\"nessie.silver.comments\").append()\n",
    "    print(\"âœ… Merge completado para Comments\")\n",
    "    \n",
    "    return comments_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21611c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INICIANDO PROCESO DE CONSOLIDACIÃ“N...\")\n",
    "\n",
    "votes_final = merge_and_consolidate_votes(votes2022_clean, votes2023_clean)\n",
    "comments_final = merge_and_consolidate_comments(comments2022_clean, comments2023_clean)\n",
    "\n",
    "print(\"\\n CONSOLIDACIÃ“N FINALIZADA EXITOSAMENTE!\")\n",
    "print(f\" Tablas creadas en Nessie Silver Layer:\")\n",
    "print(f\"   â€¢ nessie.silver.votes: {votes_final.count():,} registros\")\n",
    "print(f\"   â€¢ nessie.silver.comments: {comments_final.count():,} registros\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
